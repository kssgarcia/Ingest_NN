{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD33qLlwyqy5"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khanhlvg/tflite_raspberry_pi/blob/main/object_detection/Train_custom_model_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf2if_fGDaWc"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpJEzDG6DK2Q"
      },
      "source": [
        "# Train a custom object detection model with TensorFlow Lite Model Maker\n",
        "\n",
        "In this colab notebook, you'll learn how to use the [TensorFlow Lite Model Maker](https://www.tensorflow.org/lite/guide/model_maker) to train a custom object detection model to detect Android figurines and how to put the model on a Raspberry Pi.\n",
        "\n",
        "The Model Maker library uses *transfer learning* to simplify the process of training a TensorFlow Lite model using a custom dataset. Retraining a TensorFlow Lite model with your own custom dataset reduces the amount of training data required and will shorten the training time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRYjtwRZGBOI"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "### Install the required packages\n",
        "Start by installing the required packages, including the Model Maker package from the [GitHub repo](https://github.com/tensorflow/examples/tree/master/tensorflow_examples/lite/model_maker) and the pycocotools library you'll use for evaluation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prQ86DdtD317"
      },
      "source": [
        "Import the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "l4QQTXHHATDS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\santy\\anaconda3\\envs\\tflite-env\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "c:\\Users\\santy\\anaconda3\\envs\\tflite-env\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "c:\\Users\\santy\\anaconda3\\envs\\tflite-env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g6aQvXsD78P"
      },
      "source": [
        "### Prepare the dataset\n",
        "\n",
        "This dataset contains about 70 images of 2 type of Android figurines: an Android and an Android pig. This is an example image from the dataset.\n",
        "\n",
        "![android_figurine_sample.jpg](https://storage.googleapis.com/download.tensorflow.org/example_images/android_figurine_sample.jpg)\n",
        "\n",
        "We start with downloading the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxh3KInCFeB-"
      },
      "source": [
        "## Train the object detection model\n",
        "\n",
        "### Step 1: Load the dataset\n",
        "\n",
        "* Images in `train_data` is used to train the custom object detection model.\n",
        "* Images in `val_data` is used to check if the model can generalize well to new images that it hasn't seen before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WiAahdsQAdT7"
      },
      "outputs": [],
      "source": [
        "train_data = object_detector.DataLoader.from_pascal_voc(\n",
        "    'datasets/Plates_dataset/train',\n",
        "    'datasets/Plates_dataset/train',\n",
        "    ['Plate']\n",
        ")\n",
        "\n",
        "val_data = object_detector.DataLoader.from_pascal_voc(\n",
        "    'datasets/Plates_dataset/valid',\n",
        "    'datasets/Plates_dataset/valid',\n",
        "    ['Plate']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNRhB8N7GHXj"
      },
      "source": [
        "### Step 2: Select a model architecture\n",
        "\n",
        "EfficientDet-Lite[0-4] are a family of mobile/IoT-friendly object detection models derived from the [EfficientDet](https://arxiv.org/abs/1911.09070) architecture.\n",
        "\n",
        "Here is the performance of each EfficientDet-Lite models compared to each others.\n",
        "\n",
        "| Model architecture | Size(MB)* | Latency(ms)** | Average Precision*** |\n",
        "|--------------------|-----------|---------------|----------------------|\n",
        "| EfficientDet-Lite0 | 4.4       | 146           | 25.69%               |\n",
        "| EfficientDet-Lite1 | 5.8       | 259           | 30.55%               |\n",
        "| EfficientDet-Lite2 | 7.2       | 396           | 33.97%               |\n",
        "| EfficientDet-Lite3 | 11.4      | 716           | 37.70%               |\n",
        "| EfficientDet-Lite4 | 19.9      | 1886          | 41.96%               |\n",
        "\n",
        "<i> * Size of the integer quantized models. <br/>\n",
        "** Latency measured on Raspberry Pi 4 using 4 threads on CPU. <br/>\n",
        "*** Average Precision is the mAP (mean Average Precision) on the COCO 2017 validation dataset.\n",
        "</i>\n",
        "\n",
        "In this notebook, we use EfficientDet-Lite0 to train our model. You can choose other model architectures depending on whether speed or accuracy is more important to you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GZOojrDHAY1J"
      },
      "outputs": [],
      "source": [
        "spec = model_spec.get('efficientdet_lite0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aeDU4mIM4ft"
      },
      "source": [
        "### Step 3: Train the TensorFlow model with the training data.\n",
        "\n",
        "* Set `epochs = 20`, which means it will go through the training dataset 20 times. You can look at the validation accuracy during training and stop when you see validation loss (`val_loss`) stop decreasing to avoid overfitting.\n",
        "* Set `batch_size = 4` here so you will see that it takes 15 steps to go through the 62 images in the training dataset.\n",
        "* Set `train_whole_model=True` to fine-tune the whole model instead of just training the head layer to improve accuracy. The trade-off is that it may take longer to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MClfpsJAfda",
        "outputId": "cbfc9772-a3c7-4f60-a7af-a6032de27d2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "66/66 [==============================] - 52s 325ms/step - det_loss: 1.3567 - cls_loss: 0.8327 - box_loss: 0.0105 - reg_l2_loss: 0.0630 - loss: 1.4198 - learning_rate: 0.0065 - gradient_norm: 3.3468 - val_det_loss: 1.6353 - val_cls_loss: 1.1590 - val_box_loss: 0.0095 - val_reg_l2_loss: 0.0631 - val_loss: 1.6984\n",
            "Epoch 2/150\n",
            "66/66 [==============================] - 18s 273ms/step - det_loss: 0.8982 - cls_loss: 0.4772 - box_loss: 0.0084 - reg_l2_loss: 0.0631 - loss: 0.9613 - learning_rate: 0.0050 - gradient_norm: 4.1960 - val_det_loss: 0.9401 - val_cls_loss: 0.5252 - val_box_loss: 0.0083 - val_reg_l2_loss: 0.0631 - val_loss: 1.0033\n",
            "Epoch 3/150\n",
            "66/66 [==============================] - 18s 278ms/step - det_loss: 0.7524 - cls_loss: 0.4032 - box_loss: 0.0070 - reg_l2_loss: 0.0632 - loss: 0.8155 - learning_rate: 0.0050 - gradient_norm: 4.5290 - val_det_loss: 0.8053 - val_cls_loss: 0.4079 - val_box_loss: 0.0079 - val_reg_l2_loss: 0.0632 - val_loss: 0.8685\n",
            "Epoch 4/150\n",
            "66/66 [==============================] - 18s 278ms/step - det_loss: 0.6965 - cls_loss: 0.3810 - box_loss: 0.0063 - reg_l2_loss: 0.0632 - loss: 0.7597 - learning_rate: 0.0050 - gradient_norm: 4.4140 - val_det_loss: 0.6662 - val_cls_loss: 0.3636 - val_box_loss: 0.0061 - val_reg_l2_loss: 0.0633 - val_loss: 0.7295\n",
            "Epoch 5/150\n",
            "66/66 [==============================] - 23s 343ms/step - det_loss: 0.6468 - cls_loss: 0.3567 - box_loss: 0.0058 - reg_l2_loss: 0.0633 - loss: 0.7100 - learning_rate: 0.0050 - gradient_norm: 4.5257 - val_det_loss: 0.5980 - val_cls_loss: 0.3271 - val_box_loss: 0.0054 - val_reg_l2_loss: 0.0633 - val_loss: 0.6613\n",
            "Epoch 6/150\n",
            "66/66 [==============================] - 18s 279ms/step - det_loss: 0.6145 - cls_loss: 0.3382 - box_loss: 0.0055 - reg_l2_loss: 0.0633 - loss: 0.6779 - learning_rate: 0.0050 - gradient_norm: 4.7697 - val_det_loss: 0.5343 - val_cls_loss: 0.2809 - val_box_loss: 0.0051 - val_reg_l2_loss: 0.0634 - val_loss: 0.5976\n",
            "Epoch 7/150\n",
            "66/66 [==============================] - 19s 282ms/step - det_loss: 0.5781 - cls_loss: 0.3184 - box_loss: 0.0052 - reg_l2_loss: 0.0634 - loss: 0.6415 - learning_rate: 0.0050 - gradient_norm: 4.1718 - val_det_loss: 0.5931 - val_cls_loss: 0.3337 - val_box_loss: 0.0052 - val_reg_l2_loss: 0.0634 - val_loss: 0.6566\n",
            "Epoch 8/150\n",
            "66/66 [==============================] - 18s 271ms/step - det_loss: 0.5755 - cls_loss: 0.3199 - box_loss: 0.0051 - reg_l2_loss: 0.0635 - loss: 0.6390 - learning_rate: 0.0050 - gradient_norm: 4.4816 - val_det_loss: 0.5081 - val_cls_loss: 0.2885 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0635 - val_loss: 0.5716\n",
            "Epoch 9/150\n",
            "66/66 [==============================] - 19s 292ms/step - det_loss: 0.5579 - cls_loss: 0.3119 - box_loss: 0.0049 - reg_l2_loss: 0.0635 - loss: 0.6214 - learning_rate: 0.0050 - gradient_norm: 3.9903 - val_det_loss: 0.6061 - val_cls_loss: 0.3423 - val_box_loss: 0.0053 - val_reg_l2_loss: 0.0635 - val_loss: 0.6697\n",
            "Epoch 10/150\n",
            "66/66 [==============================] - 20s 304ms/step - det_loss: 0.5514 - cls_loss: 0.3100 - box_loss: 0.0048 - reg_l2_loss: 0.0636 - loss: 0.6150 - learning_rate: 0.0049 - gradient_norm: 4.3904 - val_det_loss: 0.6955 - val_cls_loss: 0.3632 - val_box_loss: 0.0066 - val_reg_l2_loss: 0.0636 - val_loss: 0.7591\n",
            "Epoch 11/150\n",
            "66/66 [==============================] - 18s 271ms/step - det_loss: 0.5122 - cls_loss: 0.2892 - box_loss: 0.0045 - reg_l2_loss: 0.0636 - loss: 0.5758 - learning_rate: 0.0049 - gradient_norm: 3.8431 - val_det_loss: 0.6239 - val_cls_loss: 0.3601 - val_box_loss: 0.0053 - val_reg_l2_loss: 0.0636 - val_loss: 0.6875\n",
            "Epoch 12/150\n",
            "66/66 [==============================] - 18s 276ms/step - det_loss: 0.5103 - cls_loss: 0.2876 - box_loss: 0.0045 - reg_l2_loss: 0.0637 - loss: 0.5740 - learning_rate: 0.0049 - gradient_norm: 4.0167 - val_det_loss: 0.5485 - val_cls_loss: 0.3321 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0637 - val_loss: 0.6122\n",
            "Epoch 13/150\n",
            "66/66 [==============================] - 18s 274ms/step - det_loss: 0.4997 - cls_loss: 0.2871 - box_loss: 0.0043 - reg_l2_loss: 0.0637 - loss: 0.5634 - learning_rate: 0.0049 - gradient_norm: 4.1233 - val_det_loss: 0.5432 - val_cls_loss: 0.3089 - val_box_loss: 0.0047 - val_reg_l2_loss: 0.0637 - val_loss: 0.6069\n",
            "Epoch 14/150\n",
            "66/66 [==============================] - 18s 271ms/step - det_loss: 0.4850 - cls_loss: 0.2745 - box_loss: 0.0042 - reg_l2_loss: 0.0637 - loss: 0.5488 - learning_rate: 0.0049 - gradient_norm: 4.0663 - val_det_loss: 0.5843 - val_cls_loss: 0.3078 - val_box_loss: 0.0055 - val_reg_l2_loss: 0.0637 - val_loss: 0.6480\n",
            "Epoch 15/150\n",
            "66/66 [==============================] - 20s 306ms/step - det_loss: 0.4835 - cls_loss: 0.2753 - box_loss: 0.0042 - reg_l2_loss: 0.0638 - loss: 0.5472 - learning_rate: 0.0049 - gradient_norm: 3.9460 - val_det_loss: 0.6124 - val_cls_loss: 0.3504 - val_box_loss: 0.0052 - val_reg_l2_loss: 0.0638 - val_loss: 0.6761\n",
            "Epoch 16/150\n",
            "66/66 [==============================] - 19s 293ms/step - det_loss: 0.4557 - cls_loss: 0.2614 - box_loss: 0.0039 - reg_l2_loss: 0.0638 - loss: 0.5195 - learning_rate: 0.0049 - gradient_norm: 3.9782 - val_det_loss: 0.6713 - val_cls_loss: 0.3386 - val_box_loss: 0.0067 - val_reg_l2_loss: 0.0638 - val_loss: 0.7351\n",
            "Epoch 17/150\n",
            "66/66 [==============================] - 19s 288ms/step - det_loss: 0.4596 - cls_loss: 0.2581 - box_loss: 0.0040 - reg_l2_loss: 0.0639 - loss: 0.5235 - learning_rate: 0.0049 - gradient_norm: 3.9823 - val_det_loss: 0.5480 - val_cls_loss: 0.2569 - val_box_loss: 0.0058 - val_reg_l2_loss: 0.0639 - val_loss: 0.6118\n",
            "Epoch 18/150\n",
            "66/66 [==============================] - 18s 276ms/step - det_loss: 0.4632 - cls_loss: 0.2601 - box_loss: 0.0041 - reg_l2_loss: 0.0639 - loss: 0.5271 - learning_rate: 0.0048 - gradient_norm: 3.6873 - val_det_loss: 0.5005 - val_cls_loss: 0.2725 - val_box_loss: 0.0046 - val_reg_l2_loss: 0.0639 - val_loss: 0.5644\n",
            "Epoch 19/150\n",
            "66/66 [==============================] - 18s 277ms/step - det_loss: 0.4625 - cls_loss: 0.2612 - box_loss: 0.0040 - reg_l2_loss: 0.0639 - loss: 0.5264 - learning_rate: 0.0048 - gradient_norm: 3.8826 - val_det_loss: 0.6460 - val_cls_loss: 0.3674 - val_box_loss: 0.0056 - val_reg_l2_loss: 0.0639 - val_loss: 0.7099\n",
            "Epoch 20/150\n",
            "66/66 [==============================] - 20s 302ms/step - det_loss: 0.4321 - cls_loss: 0.2518 - box_loss: 0.0036 - reg_l2_loss: 0.0640 - loss: 0.4960 - learning_rate: 0.0048 - gradient_norm: 3.4003 - val_det_loss: 0.5347 - val_cls_loss: 0.3068 - val_box_loss: 0.0046 - val_reg_l2_loss: 0.0640 - val_loss: 0.5987\n",
            "Epoch 21/150\n",
            "66/66 [==============================] - 18s 277ms/step - det_loss: 0.4362 - cls_loss: 0.2532 - box_loss: 0.0037 - reg_l2_loss: 0.0640 - loss: 0.5002 - learning_rate: 0.0048 - gradient_norm: 3.6525 - val_det_loss: 0.6618 - val_cls_loss: 0.3701 - val_box_loss: 0.0058 - val_reg_l2_loss: 0.0640 - val_loss: 0.7258\n",
            "Epoch 22/150\n",
            "66/66 [==============================] - 18s 275ms/step - det_loss: 0.4285 - cls_loss: 0.2491 - box_loss: 0.0036 - reg_l2_loss: 0.0640 - loss: 0.4925 - learning_rate: 0.0047 - gradient_norm: 3.9260 - val_det_loss: 0.5250 - val_cls_loss: 0.2993 - val_box_loss: 0.0045 - val_reg_l2_loss: 0.0640 - val_loss: 0.5891\n",
            "Epoch 23/150\n",
            "66/66 [==============================] - 18s 275ms/step - det_loss: 0.4505 - cls_loss: 0.2548 - box_loss: 0.0039 - reg_l2_loss: 0.0640 - loss: 0.5146 - learning_rate: 0.0047 - gradient_norm: 3.7668 - val_det_loss: 0.6399 - val_cls_loss: 0.4120 - val_box_loss: 0.0046 - val_reg_l2_loss: 0.0640 - val_loss: 0.7039\n",
            "Epoch 24/150\n",
            "66/66 [==============================] - 19s 291ms/step - det_loss: 0.4210 - cls_loss: 0.2440 - box_loss: 0.0035 - reg_l2_loss: 0.0641 - loss: 0.4851 - learning_rate: 0.0047 - gradient_norm: 3.9096 - val_det_loss: 0.5912 - val_cls_loss: 0.3699 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0641 - val_loss: 0.6552\n",
            "Epoch 25/150\n",
            "66/66 [==============================] - 20s 301ms/step - det_loss: 0.4112 - cls_loss: 0.2402 - box_loss: 0.0034 - reg_l2_loss: 0.0641 - loss: 0.4753 - learning_rate: 0.0047 - gradient_norm: 3.6141 - val_det_loss: 0.6591 - val_cls_loss: 0.3752 - val_box_loss: 0.0057 - val_reg_l2_loss: 0.0641 - val_loss: 0.7232\n",
            "Epoch 26/150\n",
            "66/66 [==============================] - 18s 272ms/step - det_loss: 0.4159 - cls_loss: 0.2402 - box_loss: 0.0035 - reg_l2_loss: 0.0641 - loss: 0.4800 - learning_rate: 0.0046 - gradient_norm: 3.6897 - val_det_loss: 0.6981 - val_cls_loss: 0.4205 - val_box_loss: 0.0056 - val_reg_l2_loss: 0.0641 - val_loss: 0.7622\n",
            "Epoch 27/150\n",
            "66/66 [==============================] - 18s 275ms/step - det_loss: 0.4287 - cls_loss: 0.2483 - box_loss: 0.0036 - reg_l2_loss: 0.0642 - loss: 0.4928 - learning_rate: 0.0046 - gradient_norm: 3.8114 - val_det_loss: 0.6099 - val_cls_loss: 0.3483 - val_box_loss: 0.0052 - val_reg_l2_loss: 0.0642 - val_loss: 0.6741\n",
            "Epoch 28/150\n",
            "66/66 [==============================] - 18s 274ms/step - det_loss: 0.4066 - cls_loss: 0.2323 - box_loss: 0.0035 - reg_l2_loss: 0.0642 - loss: 0.4708 - learning_rate: 0.0046 - gradient_norm: 3.9564 - val_det_loss: 0.5980 - val_cls_loss: 0.3255 - val_box_loss: 0.0054 - val_reg_l2_loss: 0.0642 - val_loss: 0.6622\n",
            "Epoch 29/150\n",
            "66/66 [==============================] - 18s 273ms/step - det_loss: 0.4058 - cls_loss: 0.2362 - box_loss: 0.0034 - reg_l2_loss: 0.0642 - loss: 0.4701 - learning_rate: 0.0046 - gradient_norm: 3.6818 - val_det_loss: 0.5270 - val_cls_loss: 0.2884 - val_box_loss: 0.0048 - val_reg_l2_loss: 0.0642 - val_loss: 0.5912\n",
            "Epoch 30/150\n",
            "66/66 [==============================] - 20s 303ms/step - det_loss: 0.3944 - cls_loss: 0.2280 - box_loss: 0.0033 - reg_l2_loss: 0.0642 - loss: 0.4587 - learning_rate: 0.0045 - gradient_norm: 3.5633 - val_det_loss: 0.5684 - val_cls_loss: 0.3550 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0642 - val_loss: 0.6327\n",
            "Epoch 31/150\n",
            "66/66 [==============================] - 19s 294ms/step - det_loss: 0.3904 - cls_loss: 0.2276 - box_loss: 0.0033 - reg_l2_loss: 0.0643 - loss: 0.4546 - learning_rate: 0.0045 - gradient_norm: 3.5144 - val_det_loss: 0.6525 - val_cls_loss: 0.3800 - val_box_loss: 0.0054 - val_reg_l2_loss: 0.0643 - val_loss: 0.7168\n",
            "Epoch 32/150\n",
            "66/66 [==============================] - 18s 275ms/step - det_loss: 0.3819 - cls_loss: 0.2228 - box_loss: 0.0032 - reg_l2_loss: 0.0643 - loss: 0.4462 - learning_rate: 0.0045 - gradient_norm: 3.3307 - val_det_loss: 0.6325 - val_cls_loss: 0.3734 - val_box_loss: 0.0052 - val_reg_l2_loss: 0.0643 - val_loss: 0.6968\n",
            "Epoch 33/150\n",
            "66/66 [==============================] - 18s 275ms/step - det_loss: 0.4008 - cls_loss: 0.2347 - box_loss: 0.0033 - reg_l2_loss: 0.0643 - loss: 0.4651 - learning_rate: 0.0044 - gradient_norm: 3.6119 - val_det_loss: 0.5880 - val_cls_loss: 0.3430 - val_box_loss: 0.0049 - val_reg_l2_loss: 0.0643 - val_loss: 0.6523\n",
            "Epoch 34/150\n",
            "66/66 [==============================] - 18s 275ms/step - det_loss: 0.3943 - cls_loss: 0.2272 - box_loss: 0.0033 - reg_l2_loss: 0.0643 - loss: 0.4587 - learning_rate: 0.0044 - gradient_norm: 3.4132 - val_det_loss: 0.7058 - val_cls_loss: 0.4262 - val_box_loss: 0.0056 - val_reg_l2_loss: 0.0643 - val_loss: 0.7702\n",
            "Epoch 35/150\n",
            "66/66 [==============================] - 20s 305ms/step - det_loss: 0.3602 - cls_loss: 0.2150 - box_loss: 0.0029 - reg_l2_loss: 0.0643 - loss: 0.4245 - learning_rate: 0.0044 - gradient_norm: 3.5420 - val_det_loss: 0.5494 - val_cls_loss: 0.3101 - val_box_loss: 0.0048 - val_reg_l2_loss: 0.0644 - val_loss: 0.6137\n",
            "Epoch 36/150\n",
            "66/66 [==============================] - 18s 276ms/step - det_loss: 0.3850 - cls_loss: 0.2229 - box_loss: 0.0032 - reg_l2_loss: 0.0644 - loss: 0.4494 - learning_rate: 0.0043 - gradient_norm: 3.4529 - val_det_loss: 0.6225 - val_cls_loss: 0.3589 - val_box_loss: 0.0053 - val_reg_l2_loss: 0.0644 - val_loss: 0.6869\n",
            "Epoch 37/150\n",
            "66/66 [==============================] - 19s 284ms/step - det_loss: 0.3800 - cls_loss: 0.2206 - box_loss: 0.0032 - reg_l2_loss: 0.0644 - loss: 0.4444 - learning_rate: 0.0043 - gradient_norm: 3.6104 - val_det_loss: 0.6603 - val_cls_loss: 0.3732 - val_box_loss: 0.0057 - val_reg_l2_loss: 0.0644 - val_loss: 0.7247\n",
            "Epoch 38/150\n",
            "66/66 [==============================] - 18s 280ms/step - det_loss: 0.3678 - cls_loss: 0.2155 - box_loss: 0.0030 - reg_l2_loss: 0.0644 - loss: 0.4322 - learning_rate: 0.0043 - gradient_norm: 3.4637 - val_det_loss: 0.6299 - val_cls_loss: 0.3839 - val_box_loss: 0.0049 - val_reg_l2_loss: 0.0644 - val_loss: 0.6943\n",
            "Epoch 39/150\n",
            "66/66 [==============================] - 19s 287ms/step - det_loss: 0.3732 - cls_loss: 0.2168 - box_loss: 0.0031 - reg_l2_loss: 0.0644 - loss: 0.4376 - learning_rate: 0.0042 - gradient_norm: 3.8163 - val_det_loss: 0.5698 - val_cls_loss: 0.3245 - val_box_loss: 0.0049 - val_reg_l2_loss: 0.0644 - val_loss: 0.6342\n",
            "Epoch 40/150\n",
            "66/66 [==============================] - 20s 307ms/step - det_loss: 0.3646 - cls_loss: 0.2127 - box_loss: 0.0030 - reg_l2_loss: 0.0644 - loss: 0.4290 - learning_rate: 0.0042 - gradient_norm: 3.5346 - val_det_loss: 0.5902 - val_cls_loss: 0.3625 - val_box_loss: 0.0046 - val_reg_l2_loss: 0.0644 - val_loss: 0.6547\n",
            "Epoch 41/150\n",
            "66/66 [==============================] - 19s 282ms/step - det_loss: 0.3539 - cls_loss: 0.2071 - box_loss: 0.0029 - reg_l2_loss: 0.0645 - loss: 0.4184 - learning_rate: 0.0041 - gradient_norm: 3.6660 - val_det_loss: 0.5535 - val_cls_loss: 0.3498 - val_box_loss: 0.0041 - val_reg_l2_loss: 0.0645 - val_loss: 0.6180\n",
            "Epoch 42/150\n",
            "66/66 [==============================] - 18s 280ms/step - det_loss: 0.3629 - cls_loss: 0.2127 - box_loss: 0.0030 - reg_l2_loss: 0.0645 - loss: 0.4274 - learning_rate: 0.0041 - gradient_norm: 3.5741 - val_det_loss: 0.5455 - val_cls_loss: 0.3190 - val_box_loss: 0.0045 - val_reg_l2_loss: 0.0645 - val_loss: 0.6100\n",
            "Epoch 43/150\n",
            "66/66 [==============================] - 18s 268ms/step - det_loss: 0.3562 - cls_loss: 0.2093 - box_loss: 0.0029 - reg_l2_loss: 0.0645 - loss: 0.4207 - learning_rate: 0.0041 - gradient_norm: 3.5705 - val_det_loss: 0.5968 - val_cls_loss: 0.3652 - val_box_loss: 0.0046 - val_reg_l2_loss: 0.0645 - val_loss: 0.6613\n",
            "Epoch 44/150\n",
            "66/66 [==============================] - 18s 270ms/step - det_loss: 0.3629 - cls_loss: 0.2149 - box_loss: 0.0030 - reg_l2_loss: 0.0645 - loss: 0.4275 - learning_rate: 0.0040 - gradient_norm: 3.5635 - val_det_loss: 0.6535 - val_cls_loss: 0.4423 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0645 - val_loss: 0.7180\n",
            "Epoch 45/150\n",
            "66/66 [==============================] - 20s 299ms/step - det_loss: 0.3655 - cls_loss: 0.2127 - box_loss: 0.0031 - reg_l2_loss: 0.0645 - loss: 0.4301 - learning_rate: 0.0040 - gradient_norm: 3.5223 - val_det_loss: 0.5436 - val_cls_loss: 0.3304 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0645 - val_loss: 0.6082\n",
            "Epoch 46/150\n",
            "66/66 [==============================] - 18s 269ms/step - det_loss: 0.3588 - cls_loss: 0.2075 - box_loss: 0.0030 - reg_l2_loss: 0.0645 - loss: 0.4233 - learning_rate: 0.0039 - gradient_norm: 3.2361 - val_det_loss: 0.4464 - val_cls_loss: 0.2644 - val_box_loss: 0.0036 - val_reg_l2_loss: 0.0645 - val_loss: 0.5110\n",
            "Epoch 47/150\n",
            "66/66 [==============================] - 19s 284ms/step - det_loss: 0.3519 - cls_loss: 0.2066 - box_loss: 0.0029 - reg_l2_loss: 0.0645 - loss: 0.4164 - learning_rate: 0.0039 - gradient_norm: 3.5496 - val_det_loss: 0.5902 - val_cls_loss: 0.3701 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0646 - val_loss: 0.6548\n",
            "Epoch 48/150\n",
            "66/66 [==============================] - 18s 269ms/step - det_loss: 0.3416 - cls_loss: 0.2035 - box_loss: 0.0028 - reg_l2_loss: 0.0646 - loss: 0.4062 - learning_rate: 0.0038 - gradient_norm: 3.3311 - val_det_loss: 0.5441 - val_cls_loss: 0.3177 - val_box_loss: 0.0045 - val_reg_l2_loss: 0.0646 - val_loss: 0.6087\n",
            "Epoch 49/150\n",
            "66/66 [==============================] - 18s 270ms/step - det_loss: 0.3221 - cls_loss: 0.1928 - box_loss: 0.0026 - reg_l2_loss: 0.0646 - loss: 0.3866 - learning_rate: 0.0038 - gradient_norm: 3.2077 - val_det_loss: 0.4794 - val_cls_loss: 0.2786 - val_box_loss: 0.0040 - val_reg_l2_loss: 0.0646 - val_loss: 0.5440\n",
            "Epoch 50/150\n",
            "66/66 [==============================] - 20s 298ms/step - det_loss: 0.3351 - cls_loss: 0.1963 - box_loss: 0.0028 - reg_l2_loss: 0.0646 - loss: 0.3997 - learning_rate: 0.0038 - gradient_norm: 3.3664 - val_det_loss: 0.6255 - val_cls_loss: 0.4101 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0646 - val_loss: 0.6901\n",
            "Epoch 51/150\n",
            "66/66 [==============================] - 18s 268ms/step - det_loss: 0.3252 - cls_loss: 0.1925 - box_loss: 0.0027 - reg_l2_loss: 0.0646 - loss: 0.3898 - learning_rate: 0.0037 - gradient_norm: 3.3539 - val_det_loss: 0.5754 - val_cls_loss: 0.3234 - val_box_loss: 0.0050 - val_reg_l2_loss: 0.0646 - val_loss: 0.6400\n",
            "Epoch 52/150\n",
            "66/66 [==============================] - 18s 270ms/step - det_loss: 0.3190 - cls_loss: 0.1910 - box_loss: 0.0026 - reg_l2_loss: 0.0646 - loss: 0.3837 - learning_rate: 0.0037 - gradient_norm: 3.2171 - val_det_loss: 0.4973 - val_cls_loss: 0.2796 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0646 - val_loss: 0.5619\n",
            "Epoch 53/150\n",
            "66/66 [==============================] - 18s 273ms/step - det_loss: 0.3314 - cls_loss: 0.1971 - box_loss: 0.0027 - reg_l2_loss: 0.0646 - loss: 0.3960 - learning_rate: 0.0036 - gradient_norm: 3.5891 - val_det_loss: 0.4967 - val_cls_loss: 0.2836 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0646 - val_loss: 0.5613\n",
            "Epoch 54/150\n",
            "66/66 [==============================] - 19s 283ms/step - det_loss: 0.3350 - cls_loss: 0.1995 - box_loss: 0.0027 - reg_l2_loss: 0.0646 - loss: 0.3997 - learning_rate: 0.0036 - gradient_norm: 3.4601 - val_det_loss: 0.5201 - val_cls_loss: 0.3047 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0646 - val_loss: 0.5848\n",
            "Epoch 55/150\n",
            "66/66 [==============================] - 20s 302ms/step - det_loss: 0.3084 - cls_loss: 0.1865 - box_loss: 0.0024 - reg_l2_loss: 0.0646 - loss: 0.3730 - learning_rate: 0.0035 - gradient_norm: 3.3086 - val_det_loss: 0.5918 - val_cls_loss: 0.3408 - val_box_loss: 0.0050 - val_reg_l2_loss: 0.0646 - val_loss: 0.6565\n",
            "Epoch 56/150\n",
            "66/66 [==============================] - 18s 270ms/step - det_loss: 0.3308 - cls_loss: 0.1965 - box_loss: 0.0027 - reg_l2_loss: 0.0646 - loss: 0.3955 - learning_rate: 0.0035 - gradient_norm: 3.3083 - val_det_loss: 0.5807 - val_cls_loss: 0.3509 - val_box_loss: 0.0046 - val_reg_l2_loss: 0.0646 - val_loss: 0.6454\n",
            "Epoch 57/150\n",
            "66/66 [==============================] - 18s 269ms/step - det_loss: 0.3300 - cls_loss: 0.1934 - box_loss: 0.0027 - reg_l2_loss: 0.0647 - loss: 0.3947 - learning_rate: 0.0034 - gradient_norm: 3.2743 - val_det_loss: 0.5306 - val_cls_loss: 0.3357 - val_box_loss: 0.0039 - val_reg_l2_loss: 0.0647 - val_loss: 0.5953\n",
            "Epoch 58/150\n",
            "66/66 [==============================] - 18s 267ms/step - det_loss: 0.3155 - cls_loss: 0.1876 - box_loss: 0.0026 - reg_l2_loss: 0.0647 - loss: 0.3802 - learning_rate: 0.0034 - gradient_norm: 3.2305 - val_det_loss: 0.5439 - val_cls_loss: 0.3314 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.6086\n",
            "Epoch 59/150\n",
            "66/66 [==============================] - 18s 267ms/step - det_loss: 0.3226 - cls_loss: 0.1946 - box_loss: 0.0026 - reg_l2_loss: 0.0647 - loss: 0.3873 - learning_rate: 0.0033 - gradient_norm: 3.4746 - val_det_loss: 0.5470 - val_cls_loss: 0.3432 - val_box_loss: 0.0041 - val_reg_l2_loss: 0.0647 - val_loss: 0.6117\n",
            "Epoch 60/150\n",
            "66/66 [==============================] - 20s 297ms/step - det_loss: 0.3147 - cls_loss: 0.1875 - box_loss: 0.0025 - reg_l2_loss: 0.0647 - loss: 0.3794 - learning_rate: 0.0033 - gradient_norm: 3.1365 - val_det_loss: 0.5713 - val_cls_loss: 0.3315 - val_box_loss: 0.0048 - val_reg_l2_loss: 0.0647 - val_loss: 0.6360\n",
            "Epoch 61/150\n",
            "66/66 [==============================] - 17s 264ms/step - det_loss: 0.3063 - cls_loss: 0.1844 - box_loss: 0.0024 - reg_l2_loss: 0.0647 - loss: 0.3710 - learning_rate: 0.0032 - gradient_norm: 3.2210 - val_det_loss: 0.4997 - val_cls_loss: 0.2942 - val_box_loss: 0.0041 - val_reg_l2_loss: 0.0647 - val_loss: 0.5644\n",
            "Epoch 62/150\n",
            "66/66 [==============================] - 19s 282ms/step - det_loss: 0.3223 - cls_loss: 0.1923 - box_loss: 0.0026 - reg_l2_loss: 0.0647 - loss: 0.3870 - learning_rate: 0.0032 - gradient_norm: 3.5154 - val_det_loss: 0.4718 - val_cls_loss: 0.2573 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5365\n",
            "Epoch 63/150\n",
            "66/66 [==============================] - 18s 271ms/step - det_loss: 0.3119 - cls_loss: 0.1833 - box_loss: 0.0026 - reg_l2_loss: 0.0647 - loss: 0.3766 - learning_rate: 0.0031 - gradient_norm: 3.5077 - val_det_loss: 0.5256 - val_cls_loss: 0.3007 - val_box_loss: 0.0045 - val_reg_l2_loss: 0.0647 - val_loss: 0.5903\n",
            "Epoch 64/150\n",
            "66/66 [==============================] - 18s 269ms/step - det_loss: 0.2974 - cls_loss: 0.1809 - box_loss: 0.0023 - reg_l2_loss: 0.0647 - loss: 0.3621 - learning_rate: 0.0031 - gradient_norm: 3.4462 - val_det_loss: 0.5198 - val_cls_loss: 0.3006 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.5845\n",
            "Epoch 65/150\n",
            "66/66 [==============================] - 20s 301ms/step - det_loss: 0.2980 - cls_loss: 0.1778 - box_loss: 0.0024 - reg_l2_loss: 0.0647 - loss: 0.3627 - learning_rate: 0.0030 - gradient_norm: 3.1617 - val_det_loss: 0.4371 - val_cls_loss: 0.2641 - val_box_loss: 0.0035 - val_reg_l2_loss: 0.0647 - val_loss: 0.5018\n",
            "Epoch 66/150\n",
            "66/66 [==============================] - 18s 269ms/step - det_loss: 0.3003 - cls_loss: 0.1796 - box_loss: 0.0024 - reg_l2_loss: 0.0647 - loss: 0.3650 - learning_rate: 0.0030 - gradient_norm: 3.5194 - val_det_loss: 0.4592 - val_cls_loss: 0.2748 - val_box_loss: 0.0037 - val_reg_l2_loss: 0.0647 - val_loss: 0.5239\n",
            "Epoch 67/150\n",
            "66/66 [==============================] - 18s 270ms/step - det_loss: 0.3000 - cls_loss: 0.1798 - box_loss: 0.0024 - reg_l2_loss: 0.0647 - loss: 0.3647 - learning_rate: 0.0029 - gradient_norm: 3.2349 - val_det_loss: 0.6023 - val_cls_loss: 0.3585 - val_box_loss: 0.0049 - val_reg_l2_loss: 0.0647 - val_loss: 0.6670\n",
            "Epoch 68/150\n",
            "66/66 [==============================] - 18s 267ms/step - det_loss: 0.2937 - cls_loss: 0.1739 - box_loss: 0.0024 - reg_l2_loss: 0.0647 - loss: 0.3585 - learning_rate: 0.0029 - gradient_norm: 3.0450 - val_det_loss: 0.5135 - val_cls_loss: 0.2975 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5782\n",
            "Epoch 69/150\n",
            "66/66 [==============================] - 19s 282ms/step - det_loss: 0.3013 - cls_loss: 0.1826 - box_loss: 0.0024 - reg_l2_loss: 0.0647 - loss: 0.3660 - learning_rate: 0.0028 - gradient_norm: 3.4781 - val_det_loss: 0.4616 - val_cls_loss: 0.2618 - val_box_loss: 0.0040 - val_reg_l2_loss: 0.0647 - val_loss: 0.5264\n",
            "Epoch 70/150\n",
            "66/66 [==============================] - 20s 298ms/step - det_loss: 0.2928 - cls_loss: 0.1734 - box_loss: 0.0024 - reg_l2_loss: 0.0647 - loss: 0.3575 - learning_rate: 0.0028 - gradient_norm: 3.2166 - val_det_loss: 0.4826 - val_cls_loss: 0.2745 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0647 - val_loss: 0.5474\n",
            "Epoch 71/150\n",
            "66/66 [==============================] - 18s 271ms/step - det_loss: 0.2879 - cls_loss: 0.1729 - box_loss: 0.0023 - reg_l2_loss: 0.0647 - loss: 0.3527 - learning_rate: 0.0027 - gradient_norm: 3.2353 - val_det_loss: 0.5351 - val_cls_loss: 0.3026 - val_box_loss: 0.0047 - val_reg_l2_loss: 0.0647 - val_loss: 0.5999\n",
            "Epoch 72/150\n",
            "66/66 [==============================] - 18s 269ms/step - det_loss: 0.2950 - cls_loss: 0.1737 - box_loss: 0.0024 - reg_l2_loss: 0.0647 - loss: 0.3597 - learning_rate: 0.0027 - gradient_norm: 3.1432 - val_det_loss: 0.5355 - val_cls_loss: 0.3086 - val_box_loss: 0.0045 - val_reg_l2_loss: 0.0647 - val_loss: 0.6003\n",
            "Epoch 73/150\n",
            "66/66 [==============================] - 18s 271ms/step - det_loss: 0.2873 - cls_loss: 0.1742 - box_loss: 0.0023 - reg_l2_loss: 0.0647 - loss: 0.3520 - learning_rate: 0.0026 - gradient_norm: 3.4206 - val_det_loss: 0.4994 - val_cls_loss: 0.2941 - val_box_loss: 0.0041 - val_reg_l2_loss: 0.0647 - val_loss: 0.5641\n",
            "Epoch 74/150\n",
            "66/66 [==============================] - 18s 268ms/step - det_loss: 0.2902 - cls_loss: 0.1760 - box_loss: 0.0023 - reg_l2_loss: 0.0647 - loss: 0.3550 - learning_rate: 0.0026 - gradient_norm: 3.2948 - val_det_loss: 0.5164 - val_cls_loss: 0.2926 - val_box_loss: 0.0045 - val_reg_l2_loss: 0.0647 - val_loss: 0.5811\n",
            "Epoch 75/150\n",
            "66/66 [==============================] - 20s 299ms/step - det_loss: 0.2884 - cls_loss: 0.1738 - box_loss: 0.0023 - reg_l2_loss: 0.0647 - loss: 0.3531 - learning_rate: 0.0025 - gradient_norm: 3.2852 - val_det_loss: 0.5167 - val_cls_loss: 0.3110 - val_box_loss: 0.0041 - val_reg_l2_loss: 0.0647 - val_loss: 0.5815\n",
            "Epoch 76/150\n",
            "66/66 [==============================] - 18s 266ms/step - det_loss: 0.2835 - cls_loss: 0.1745 - box_loss: 0.0022 - reg_l2_loss: 0.0647 - loss: 0.3483 - learning_rate: 0.0024 - gradient_norm: 3.0953 - val_det_loss: 0.4812 - val_cls_loss: 0.2873 - val_box_loss: 0.0039 - val_reg_l2_loss: 0.0647 - val_loss: 0.5459\n",
            "Epoch 77/150\n",
            "66/66 [==============================] - 19s 283ms/step - det_loss: 0.2906 - cls_loss: 0.1741 - box_loss: 0.0023 - reg_l2_loss: 0.0647 - loss: 0.3553 - learning_rate: 0.0024 - gradient_norm: 3.3052 - val_det_loss: 0.4467 - val_cls_loss: 0.2777 - val_box_loss: 0.0034 - val_reg_l2_loss: 0.0647 - val_loss: 0.5114\n",
            "Epoch 78/150\n",
            "66/66 [==============================] - 18s 269ms/step - det_loss: 0.2933 - cls_loss: 0.1789 - box_loss: 0.0023 - reg_l2_loss: 0.0647 - loss: 0.3581 - learning_rate: 0.0023 - gradient_norm: 3.2450 - val_det_loss: 0.5355 - val_cls_loss: 0.3372 - val_box_loss: 0.0040 - val_reg_l2_loss: 0.0647 - val_loss: 0.6003\n",
            "Epoch 79/150\n",
            "66/66 [==============================] - 18s 269ms/step - det_loss: 0.2948 - cls_loss: 0.1784 - box_loss: 0.0023 - reg_l2_loss: 0.0647 - loss: 0.3595 - learning_rate: 0.0023 - gradient_norm: 3.6188 - val_det_loss: 0.4942 - val_cls_loss: 0.2961 - val_box_loss: 0.0040 - val_reg_l2_loss: 0.0647 - val_loss: 0.5590\n",
            "Epoch 80/150\n",
            "66/66 [==============================] - 19s 295ms/step - det_loss: 0.2653 - cls_loss: 0.1589 - box_loss: 0.0021 - reg_l2_loss: 0.0647 - loss: 0.3301 - learning_rate: 0.0022 - gradient_norm: 2.9893 - val_det_loss: 0.4490 - val_cls_loss: 0.2628 - val_box_loss: 0.0037 - val_reg_l2_loss: 0.0647 - val_loss: 0.5137\n",
            "Epoch 81/150\n",
            "66/66 [==============================] - 18s 271ms/step - det_loss: 0.2896 - cls_loss: 0.1769 - box_loss: 0.0023 - reg_l2_loss: 0.0647 - loss: 0.3544 - learning_rate: 0.0022 - gradient_norm: 3.3424 - val_det_loss: 0.4263 - val_cls_loss: 0.2558 - val_box_loss: 0.0034 - val_reg_l2_loss: 0.0647 - val_loss: 0.4910\n",
            "Epoch 82/150\n",
            "66/66 [==============================] - 18s 270ms/step - det_loss: 0.2657 - cls_loss: 0.1601 - box_loss: 0.0021 - reg_l2_loss: 0.0647 - loss: 0.3304 - learning_rate: 0.0021 - gradient_norm: 2.9920 - val_det_loss: 0.5213 - val_cls_loss: 0.3199 - val_box_loss: 0.0040 - val_reg_l2_loss: 0.0647 - val_loss: 0.5860\n",
            "Epoch 83/150\n",
            "66/66 [==============================] - 17s 266ms/step - det_loss: 0.2992 - cls_loss: 0.1834 - box_loss: 0.0023 - reg_l2_loss: 0.0647 - loss: 0.3639 - learning_rate: 0.0021 - gradient_norm: 3.6749 - val_det_loss: 0.5292 - val_cls_loss: 0.3162 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5940\n",
            "Epoch 84/150\n",
            "66/66 [==============================] - 19s 281ms/step - det_loss: 0.2787 - cls_loss: 0.1698 - box_loss: 0.0022 - reg_l2_loss: 0.0648 - loss: 0.3434 - learning_rate: 0.0020 - gradient_norm: 3.0860 - val_det_loss: 0.5163 - val_cls_loss: 0.3050 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0647 - val_loss: 0.5810\n",
            "Epoch 85/150\n",
            "66/66 [==============================] - 20s 300ms/step - det_loss: 0.2784 - cls_loss: 0.1683 - box_loss: 0.0022 - reg_l2_loss: 0.0647 - loss: 0.3431 - learning_rate: 0.0020 - gradient_norm: 3.0811 - val_det_loss: 0.4846 - val_cls_loss: 0.2733 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0647 - val_loss: 0.5494\n",
            "Epoch 86/150\n",
            "66/66 [==============================] - 18s 266ms/step - det_loss: 0.2656 - cls_loss: 0.1633 - box_loss: 0.0020 - reg_l2_loss: 0.0647 - loss: 0.3304 - learning_rate: 0.0019 - gradient_norm: 3.0435 - val_det_loss: 0.5116 - val_cls_loss: 0.2949 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5764\n",
            "Epoch 87/150\n",
            "66/66 [==============================] - 18s 269ms/step - det_loss: 0.2669 - cls_loss: 0.1607 - box_loss: 0.0021 - reg_l2_loss: 0.0647 - loss: 0.3316 - learning_rate: 0.0019 - gradient_norm: 3.1611 - val_det_loss: 0.4994 - val_cls_loss: 0.2795 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.5641\n",
            "Epoch 88/150\n",
            "66/66 [==============================] - 18s 269ms/step - det_loss: 0.2811 - cls_loss: 0.1718 - box_loss: 0.0022 - reg_l2_loss: 0.0647 - loss: 0.3458 - learning_rate: 0.0018 - gradient_norm: 3.3820 - val_det_loss: 0.4846 - val_cls_loss: 0.2761 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0647 - val_loss: 0.5494\n",
            "Epoch 89/150\n",
            "66/66 [==============================] - 18s 268ms/step - det_loss: 0.2686 - cls_loss: 0.1652 - box_loss: 0.0021 - reg_l2_loss: 0.0647 - loss: 0.3334 - learning_rate: 0.0018 - gradient_norm: 3.0888 - val_det_loss: 0.5790 - val_cls_loss: 0.3187 - val_box_loss: 0.0052 - val_reg_l2_loss: 0.0647 - val_loss: 0.6438\n",
            "Epoch 90/150\n",
            "66/66 [==============================] - 20s 297ms/step - det_loss: 0.2645 - cls_loss: 0.1598 - box_loss: 0.0021 - reg_l2_loss: 0.0647 - loss: 0.3293 - learning_rate: 0.0017 - gradient_norm: 3.0675 - val_det_loss: 0.5540 - val_cls_loss: 0.3178 - val_box_loss: 0.0047 - val_reg_l2_loss: 0.0647 - val_loss: 0.6187\n",
            "Epoch 91/150\n",
            "66/66 [==============================] - 18s 266ms/step - det_loss: 0.2764 - cls_loss: 0.1671 - box_loss: 0.0022 - reg_l2_loss: 0.0647 - loss: 0.3411 - learning_rate: 0.0017 - gradient_norm: 3.0997 - val_det_loss: 0.5511 - val_cls_loss: 0.3333 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.6159\n",
            "Epoch 92/150\n",
            "66/66 [==============================] - 19s 282ms/step - det_loss: 0.2710 - cls_loss: 0.1634 - box_loss: 0.0022 - reg_l2_loss: 0.0647 - loss: 0.3358 - learning_rate: 0.0016 - gradient_norm: 3.0517 - val_det_loss: 0.5258 - val_cls_loss: 0.3126 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5905\n",
            "Epoch 93/150\n",
            "66/66 [==============================] - 18s 266ms/step - det_loss: 0.2615 - cls_loss: 0.1591 - box_loss: 0.0020 - reg_l2_loss: 0.0647 - loss: 0.3262 - learning_rate: 0.0016 - gradient_norm: 3.1167 - val_det_loss: 0.4674 - val_cls_loss: 0.2672 - val_box_loss: 0.0040 - val_reg_l2_loss: 0.0647 - val_loss: 0.5322\n",
            "Epoch 94/150\n",
            "66/66 [==============================] - 18s 266ms/step - det_loss: 0.2711 - cls_loss: 0.1628 - box_loss: 0.0022 - reg_l2_loss: 0.0647 - loss: 0.3358 - learning_rate: 0.0015 - gradient_norm: 3.1187 - val_det_loss: 0.4647 - val_cls_loss: 0.2620 - val_box_loss: 0.0041 - val_reg_l2_loss: 0.0647 - val_loss: 0.5294\n",
            "Epoch 95/150\n",
            "66/66 [==============================] - 20s 296ms/step - det_loss: 0.2717 - cls_loss: 0.1647 - box_loss: 0.0021 - reg_l2_loss: 0.0647 - loss: 0.3364 - learning_rate: 0.0015 - gradient_norm: 3.3112 - val_det_loss: 0.4739 - val_cls_loss: 0.2745 - val_box_loss: 0.0040 - val_reg_l2_loss: 0.0647 - val_loss: 0.5386\n",
            "Epoch 96/150\n",
            "66/66 [==============================] - 18s 271ms/step - det_loss: 0.2617 - cls_loss: 0.1602 - box_loss: 0.0020 - reg_l2_loss: 0.0647 - loss: 0.3264 - learning_rate: 0.0014 - gradient_norm: 2.8188 - val_det_loss: 0.4941 - val_cls_loss: 0.3031 - val_box_loss: 0.0038 - val_reg_l2_loss: 0.0647 - val_loss: 0.5588\n",
            "Epoch 97/150\n",
            "66/66 [==============================] - 18s 276ms/step - det_loss: 0.2594 - cls_loss: 0.1579 - box_loss: 0.0020 - reg_l2_loss: 0.0647 - loss: 0.3241 - learning_rate: 0.0014 - gradient_norm: 3.1965 - val_det_loss: 0.4993 - val_cls_loss: 0.2902 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0647 - val_loss: 0.5640\n",
            "Epoch 98/150\n",
            "66/66 [==============================] - 18s 269ms/step - det_loss: 0.2446 - cls_loss: 0.1488 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3094 - learning_rate: 0.0013 - gradient_norm: 2.9027 - val_det_loss: 0.4789 - val_cls_loss: 0.2805 - val_box_loss: 0.0040 - val_reg_l2_loss: 0.0647 - val_loss: 0.5437\n",
            "Epoch 99/150\n",
            "66/66 [==============================] - 18s 266ms/step - det_loss: 0.2501 - cls_loss: 0.1559 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3148 - learning_rate: 0.0013 - gradient_norm: 3.2251 - val_det_loss: 0.5328 - val_cls_loss: 0.3061 - val_box_loss: 0.0045 - val_reg_l2_loss: 0.0647 - val_loss: 0.5975\n",
            "Epoch 100/150\n",
            "66/66 [==============================] - 20s 311ms/step - det_loss: 0.2589 - cls_loss: 0.1586 - box_loss: 0.0020 - reg_l2_loss: 0.0647 - loss: 0.3237 - learning_rate: 0.0012 - gradient_norm: 3.0820 - val_det_loss: 0.5093 - val_cls_loss: 0.2963 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5741\n",
            "Epoch 101/150\n",
            "66/66 [==============================] - 18s 270ms/step - det_loss: 0.2638 - cls_loss: 0.1563 - box_loss: 0.0021 - reg_l2_loss: 0.0647 - loss: 0.3285 - learning_rate: 0.0012 - gradient_norm: 3.2093 - val_det_loss: 0.5259 - val_cls_loss: 0.3055 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.5907\n",
            "Epoch 102/150\n",
            "66/66 [==============================] - 18s 270ms/step - det_loss: 0.2535 - cls_loss: 0.1526 - box_loss: 0.0020 - reg_l2_loss: 0.0647 - loss: 0.3183 - learning_rate: 0.0012 - gradient_norm: 3.0429 - val_det_loss: 0.5199 - val_cls_loss: 0.3027 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5847\n",
            "Epoch 103/150\n",
            "66/66 [==============================] - 18s 269ms/step - det_loss: 0.2541 - cls_loss: 0.1547 - box_loss: 0.0020 - reg_l2_loss: 0.0647 - loss: 0.3188 - learning_rate: 0.0011 - gradient_norm: 3.2767 - val_det_loss: 0.4832 - val_cls_loss: 0.2786 - val_box_loss: 0.0041 - val_reg_l2_loss: 0.0647 - val_loss: 0.5480\n",
            "Epoch 104/150\n",
            "66/66 [==============================] - 18s 272ms/step - det_loss: 0.2478 - cls_loss: 0.1518 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3125 - learning_rate: 0.0011 - gradient_norm: 2.7575 - val_det_loss: 0.5060 - val_cls_loss: 0.2915 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5707\n",
            "Epoch 105/150\n",
            "66/66 [==============================] - 20s 302ms/step - det_loss: 0.2422 - cls_loss: 0.1487 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3070 - learning_rate: 0.0010 - gradient_norm: 2.8166 - val_det_loss: 0.5388 - val_cls_loss: 0.3108 - val_box_loss: 0.0046 - val_reg_l2_loss: 0.0647 - val_loss: 0.6036\n",
            "Epoch 106/150\n",
            "66/66 [==============================] - 18s 272ms/step - det_loss: 0.2390 - cls_loss: 0.1487 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3037 - learning_rate: 9.7988e-04 - gradient_norm: 3.0242 - val_det_loss: 0.4962 - val_cls_loss: 0.2801 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5609\n",
            "Epoch 107/150\n",
            "66/66 [==============================] - 19s 287ms/step - det_loss: 0.2582 - cls_loss: 0.1592 - box_loss: 0.0020 - reg_l2_loss: 0.0647 - loss: 0.3229 - learning_rate: 9.3837e-04 - gradient_norm: 3.3902 - val_det_loss: 0.5068 - val_cls_loss: 0.2928 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5715\n",
            "Epoch 108/150\n",
            "66/66 [==============================] - 18s 272ms/step - det_loss: 0.2480 - cls_loss: 0.1521 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3128 - learning_rate: 8.9756e-04 - gradient_norm: 3.2299 - val_det_loss: 0.4827 - val_cls_loss: 0.2786 - val_box_loss: 0.0041 - val_reg_l2_loss: 0.0647 - val_loss: 0.5474\n",
            "Epoch 109/150\n",
            "66/66 [==============================] - 18s 269ms/step - det_loss: 0.2401 - cls_loss: 0.1469 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3048 - learning_rate: 8.5746e-04 - gradient_norm: 2.7248 - val_det_loss: 0.4985 - val_cls_loss: 0.2836 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5632\n",
            "Epoch 110/150\n",
            "66/66 [==============================] - 20s 304ms/step - det_loss: 0.2499 - cls_loss: 0.1527 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3146 - learning_rate: 8.1809e-04 - gradient_norm: 3.0373 - val_det_loss: 0.4854 - val_cls_loss: 0.2661 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.5501\n",
            "Epoch 111/150\n",
            "66/66 [==============================] - 18s 271ms/step - det_loss: 0.2374 - cls_loss: 0.1464 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3021 - learning_rate: 7.7947e-04 - gradient_norm: 3.0453 - val_det_loss: 0.5169 - val_cls_loss: 0.2980 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.5816\n",
            "Epoch 112/150\n",
            "66/66 [==============================] - 18s 277ms/step - det_loss: 0.2466 - cls_loss: 0.1531 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3113 - learning_rate: 7.4162e-04 - gradient_norm: 2.9878 - val_det_loss: 0.5431 - val_cls_loss: 0.3127 - val_box_loss: 0.0046 - val_reg_l2_loss: 0.0647 - val_loss: 0.6078\n",
            "Epoch 113/150\n",
            "66/66 [==============================] - 18s 270ms/step - det_loss: 0.2473 - cls_loss: 0.1521 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3120 - learning_rate: 7.0454e-04 - gradient_norm: 3.1804 - val_det_loss: 0.5105 - val_cls_loss: 0.2923 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.5752\n",
            "Epoch 114/150\n",
            "66/66 [==============================] - 19s 285ms/step - det_loss: 0.2345 - cls_loss: 0.1451 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.2992 - learning_rate: 6.6827e-04 - gradient_norm: 2.7854 - val_det_loss: 0.4792 - val_cls_loss: 0.2725 - val_box_loss: 0.0041 - val_reg_l2_loss: 0.0647 - val_loss: 0.5439\n",
            "Epoch 115/150\n",
            "66/66 [==============================] - 20s 305ms/step - det_loss: 0.2369 - cls_loss: 0.1478 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3016 - learning_rate: 6.3281e-04 - gradient_norm: 3.0757 - val_det_loss: 0.5153 - val_cls_loss: 0.2852 - val_box_loss: 0.0046 - val_reg_l2_loss: 0.0647 - val_loss: 0.5800\n",
            "Epoch 116/150\n",
            "66/66 [==============================] - 18s 270ms/step - det_loss: 0.2495 - cls_loss: 0.1557 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3142 - learning_rate: 5.9817e-04 - gradient_norm: 2.9476 - val_det_loss: 0.5005 - val_cls_loss: 0.2822 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.5652\n",
            "Epoch 117/150\n",
            "66/66 [==============================] - 18s 277ms/step - det_loss: 0.2354 - cls_loss: 0.1446 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3001 - learning_rate: 5.6439e-04 - gradient_norm: 2.8393 - val_det_loss: 0.5037 - val_cls_loss: 0.2839 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.5684\n",
            "Epoch 118/150\n",
            "66/66 [==============================] - 18s 277ms/step - det_loss: 0.2456 - cls_loss: 0.1528 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3103 - learning_rate: 5.3146e-04 - gradient_norm: 3.0139 - val_det_loss: 0.4899 - val_cls_loss: 0.2680 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.5547\n",
            "Epoch 119/150\n",
            "66/66 [==============================] - 18s 274ms/step - det_loss: 0.2479 - cls_loss: 0.1511 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3126 - learning_rate: 4.9941e-04 - gradient_norm: 3.1431 - val_det_loss: 0.4983 - val_cls_loss: 0.2757 - val_box_loss: 0.0045 - val_reg_l2_loss: 0.0647 - val_loss: 0.5630\n",
            "Epoch 120/150\n",
            "66/66 [==============================] - 20s 304ms/step - det_loss: 0.2407 - cls_loss: 0.1519 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3054 - learning_rate: 4.6825e-04 - gradient_norm: 3.0892 - val_det_loss: 0.4989 - val_cls_loss: 0.2838 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5636\n",
            "Epoch 121/150\n",
            "66/66 [==============================] - 18s 272ms/step - det_loss: 0.2380 - cls_loss: 0.1469 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3027 - learning_rate: 4.3799e-04 - gradient_norm: 2.9323 - val_det_loss: 0.5223 - val_cls_loss: 0.2932 - val_box_loss: 0.0046 - val_reg_l2_loss: 0.0647 - val_loss: 0.5870\n",
            "Epoch 122/150\n",
            "66/66 [==============================] - 19s 293ms/step - det_loss: 0.2547 - cls_loss: 0.1575 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3194 - learning_rate: 4.0865e-04 - gradient_norm: 3.1446 - val_det_loss: 0.5177 - val_cls_loss: 0.2981 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.5824\n",
            "Epoch 123/150\n",
            "66/66 [==============================] - 18s 275ms/step - det_loss: 0.2373 - cls_loss: 0.1467 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3020 - learning_rate: 3.8024e-04 - gradient_norm: 2.9539 - val_det_loss: 0.4958 - val_cls_loss: 0.2861 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0647 - val_loss: 0.5605\n",
            "Epoch 124/150\n",
            "66/66 [==============================] - 18s 274ms/step - det_loss: 0.2375 - cls_loss: 0.1472 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3022 - learning_rate: 3.5277e-04 - gradient_norm: 3.0972 - val_det_loss: 0.5132 - val_cls_loss: 0.2928 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.5779\n",
            "Epoch 125/150\n",
            "66/66 [==============================] - 20s 306ms/step - det_loss: 0.2273 - cls_loss: 0.1415 - box_loss: 0.0017 - reg_l2_loss: 0.0647 - loss: 0.2920 - learning_rate: 3.2625e-04 - gradient_norm: 2.7797 - val_det_loss: 0.4991 - val_cls_loss: 0.2864 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5638\n",
            "Epoch 126/150\n",
            "66/66 [==============================] - 18s 275ms/step - det_loss: 0.2450 - cls_loss: 0.1538 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3097 - learning_rate: 3.0070e-04 - gradient_norm: 3.1826 - val_det_loss: 0.5118 - val_cls_loss: 0.2968 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5765\n",
            "Epoch 127/150\n",
            "66/66 [==============================] - 18s 281ms/step - det_loss: 0.2416 - cls_loss: 0.1481 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3063 - learning_rate: 2.7613e-04 - gradient_norm: 2.7953 - val_det_loss: 0.5278 - val_cls_loss: 0.3064 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.5925\n",
            "Epoch 128/150\n",
            "66/66 [==============================] - 18s 278ms/step - det_loss: 0.2366 - cls_loss: 0.1450 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3013 - learning_rate: 2.5255e-04 - gradient_norm: 2.9669 - val_det_loss: 0.5606 - val_cls_loss: 0.3405 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.6253\n",
            "Epoch 129/150\n",
            "66/66 [==============================] - 19s 289ms/step - det_loss: 0.2288 - cls_loss: 0.1443 - box_loss: 0.0017 - reg_l2_loss: 0.0647 - loss: 0.2935 - learning_rate: 2.2997e-04 - gradient_norm: 2.7327 - val_det_loss: 0.5445 - val_cls_loss: 0.3246 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.6092\n",
            "Epoch 130/150\n",
            "66/66 [==============================] - 20s 304ms/step - det_loss: 0.2400 - cls_loss: 0.1461 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3047 - learning_rate: 2.0839e-04 - gradient_norm: 2.8906 - val_det_loss: 0.5331 - val_cls_loss: 0.3133 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.5978\n",
            "Epoch 131/150\n",
            "66/66 [==============================] - 18s 278ms/step - det_loss: 0.2393 - cls_loss: 0.1487 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3040 - learning_rate: 1.8784e-04 - gradient_norm: 3.1396 - val_det_loss: 0.5243 - val_cls_loss: 0.3073 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5890\n",
            "Epoch 132/150\n",
            "66/66 [==============================] - 18s 279ms/step - det_loss: 0.2354 - cls_loss: 0.1448 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3001 - learning_rate: 1.6831e-04 - gradient_norm: 2.9717 - val_det_loss: 0.5194 - val_cls_loss: 0.3018 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.5841\n",
            "Epoch 133/150\n",
            "66/66 [==============================] - 18s 278ms/step - det_loss: 0.2402 - cls_loss: 0.1497 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3049 - learning_rate: 1.4982e-04 - gradient_norm: 2.9383 - val_det_loss: 0.5159 - val_cls_loss: 0.2991 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5806\n",
            "Epoch 134/150\n",
            "66/66 [==============================] - 18s 277ms/step - det_loss: 0.2417 - cls_loss: 0.1495 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3064 - learning_rate: 1.3237e-04 - gradient_norm: 2.9938 - val_det_loss: 0.5253 - val_cls_loss: 0.3058 - val_box_loss: 0.0044 - val_reg_l2_loss: 0.0647 - val_loss: 0.5900\n",
            "Epoch 135/150\n",
            "66/66 [==============================] - 20s 305ms/step - det_loss: 0.2354 - cls_loss: 0.1439 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3001 - learning_rate: 1.1598e-04 - gradient_norm: 3.1188 - val_det_loss: 0.5307 - val_cls_loss: 0.3144 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5954\n",
            "Epoch 136/150\n",
            "66/66 [==============================] - 18s 280ms/step - det_loss: 0.2306 - cls_loss: 0.1432 - box_loss: 0.0017 - reg_l2_loss: 0.0647 - loss: 0.2953 - learning_rate: 1.0064e-04 - gradient_norm: 2.9899 - val_det_loss: 0.5148 - val_cls_loss: 0.3047 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0647 - val_loss: 0.5795\n",
            "Epoch 137/150\n",
            "66/66 [==============================] - 19s 292ms/step - det_loss: 0.2335 - cls_loss: 0.1447 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.2982 - learning_rate: 8.6375e-05 - gradient_norm: 2.9578 - val_det_loss: 0.5087 - val_cls_loss: 0.2992 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0647 - val_loss: 0.5734\n",
            "Epoch 138/150\n",
            "66/66 [==============================] - 18s 278ms/step - det_loss: 0.2459 - cls_loss: 0.1513 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3106 - learning_rate: 7.3180e-05 - gradient_norm: 3.1734 - val_det_loss: 0.5136 - val_cls_loss: 0.3035 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0647 - val_loss: 0.5783\n",
            "Epoch 139/150\n",
            "66/66 [==============================] - 18s 274ms/step - det_loss: 0.2388 - cls_loss: 0.1470 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3035 - learning_rate: 6.1065e-05 - gradient_norm: 2.9350 - val_det_loss: 0.5089 - val_cls_loss: 0.3000 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0647 - val_loss: 0.5736\n",
            "Epoch 140/150\n",
            "66/66 [==============================] - 20s 311ms/step - det_loss: 0.2310 - cls_loss: 0.1426 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.2957 - learning_rate: 5.0033e-05 - gradient_norm: 3.1029 - val_det_loss: 0.5120 - val_cls_loss: 0.3020 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0647 - val_loss: 0.5767\n",
            "Epoch 141/150\n",
            "66/66 [==============================] - 18s 276ms/step - det_loss: 0.2444 - cls_loss: 0.1483 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3091 - learning_rate: 4.0091e-05 - gradient_norm: 3.0402 - val_det_loss: 0.5071 - val_cls_loss: 0.2986 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0647 - val_loss: 0.5717\n",
            "Epoch 142/150\n",
            "66/66 [==============================] - 18s 274ms/step - det_loss: 0.2319 - cls_loss: 0.1438 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.2966 - learning_rate: 3.1242e-05 - gradient_norm: 2.9942 - val_det_loss: 0.5079 - val_cls_loss: 0.2976 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0647 - val_loss: 0.5726\n",
            "Epoch 143/150\n",
            "66/66 [==============================] - 18s 274ms/step - det_loss: 0.2427 - cls_loss: 0.1470 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3073 - learning_rate: 2.3490e-05 - gradient_norm: 2.9730 - val_det_loss: 0.5134 - val_cls_loss: 0.3032 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0647 - val_loss: 0.5781\n",
            "Epoch 144/150\n",
            "66/66 [==============================] - 19s 289ms/step - det_loss: 0.2349 - cls_loss: 0.1450 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.2995 - learning_rate: 1.6840e-05 - gradient_norm: 2.9164 - val_det_loss: 0.5155 - val_cls_loss: 0.3040 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0647 - val_loss: 0.5802\n",
            "Epoch 145/150\n",
            "66/66 [==============================] - 20s 305ms/step - det_loss: 0.2312 - cls_loss: 0.1416 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.2959 - learning_rate: 1.1293e-05 - gradient_norm: 2.8885 - val_det_loss: 0.5176 - val_cls_loss: 0.3053 - val_box_loss: 0.0042 - val_reg_l2_loss: 0.0647 - val_loss: 0.5823\n",
            "Epoch 146/150\n",
            "66/66 [==============================] - 18s 277ms/step - det_loss: 0.2310 - cls_loss: 0.1424 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.2956 - learning_rate: 6.8525e-06 - gradient_norm: 2.8725 - val_det_loss: 0.5156 - val_cls_loss: 0.3026 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5802\n",
            "Epoch 147/150\n",
            "66/66 [==============================] - 18s 274ms/step - det_loss: 0.2469 - cls_loss: 0.1530 - box_loss: 0.0019 - reg_l2_loss: 0.0647 - loss: 0.3116 - learning_rate: 3.5204e-06 - gradient_norm: 2.9427 - val_det_loss: 0.5184 - val_cls_loss: 0.3056 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5831\n",
            "Epoch 148/150\n",
            "66/66 [==============================] - 18s 276ms/step - det_loss: 0.2388 - cls_loss: 0.1488 - box_loss: 0.0018 - reg_l2_loss: 0.0647 - loss: 0.3035 - learning_rate: 1.2981e-06 - gradient_norm: 3.0459 - val_det_loss: 0.5215 - val_cls_loss: 0.3077 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5862\n",
            "Epoch 149/150\n",
            "66/66 [==============================] - 18s 272ms/step - det_loss: 0.2276 - cls_loss: 0.1416 - box_loss: 0.0017 - reg_l2_loss: 0.0647 - loss: 0.2923 - learning_rate: 1.8663e-07 - gradient_norm: 2.7743 - val_det_loss: 0.5235 - val_cls_loss: 0.3089 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5882\n",
            "Epoch 150/150\n",
            "66/66 [==============================] - 20s 303ms/step - det_loss: 0.2326 - cls_loss: 0.1453 - box_loss: 0.0017 - reg_l2_loss: 0.0647 - loss: 0.2973 - learning_rate: 1.8638e-07 - gradient_norm: 2.9874 - val_det_loss: 0.5229 - val_cls_loss: 0.3097 - val_box_loss: 0.0043 - val_reg_l2_loss: 0.0647 - val_loss: 0.5876\n"
          ]
        }
      ],
      "source": [
        "model = object_detector.create(train_data, model_spec=spec, batch_size=4, train_whole_model=True, epochs=150, validation_data=val_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB4hKeerMmh4"
      },
      "source": [
        "### Step 4. Evaluate the model with the validation data.\n",
        "\n",
        "After training the object detection model using the images in the training dataset, use the 10 images in the validation dataset to evaluate how the model performs against new data it has never seen before.\n",
        "\n",
        "As the default batch size is 64, it will take 1 step to go through the 10 images in the validation dataset.\n",
        "\n",
        "The evaluation metrics are same as [COCO](https://cocodataset.org/#detection-eval)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUqEpcYwAg8L",
        "outputId": "b359dc94-4906-4b5b-e022-77030b7a122f"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "The size of the validation_data (0) couldn't be smaller than batch_size (64). To solve this problem, set the batch_size smaller or increase the size of the validation_data.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\santy\\anaconda3\\envs\\tflite-env\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\object_detector.py:138\u001b[0m, in \u001b[0;36mObjectDetector.evaluate\u001b[1;34m(self, data, batch_size)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# TODO(b/171449557): Upstream this to the parent class.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m steps \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 138\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe size of the validation_data (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) couldn\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mt be \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    139\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmaller than batch_size (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m). To solve this problem, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    140\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset the batch_size smaller or increase the size of the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    141\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_data.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(data), batch_size))\n\u001b[0;32m    143\u001b[0m eval_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_spec\u001b[38;5;241m.\u001b[39mevaluate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, ds, steps,\n\u001b[0;32m    144\u001b[0m                                         data\u001b[38;5;241m.\u001b[39mannotations_json_file)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# Set back drop_remainder=True since it must be True during training.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Otherwise it will fail.\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: The size of the validation_data (0) couldn't be smaller than batch_size (64). To solve this problem, set the batch_size smaller or increase the size of the validation_data."
          ]
        }
      ],
      "source": [
        "model.evaluate(val_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NARVYk9rGLIl"
      },
      "source": [
        "### Step 5: Export as a TensorFlow Lite model.\n",
        "\n",
        "Export the trained object detection model to the TensorFlow Lite format by specifying which folder you want to export the quantized model to. The default post-training quantization technique is [full integer quantization](https://www.tensorflow.org/lite/performance/post_training_integer_quant). This allows the TensorFlow Lite model to be smaller, run faster on Raspberry Pi CPU and also compatible with the Google Coral EdgeTPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_u3eFxoBAiqE"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='.', tflite_filename='android.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "module 'tflite_model_maker.object_detector' has no attribute 'ExportFormat'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./saved_model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mexport(export_dir\u001b[38;5;241m=\u001b[39mmodel_path, export_format\u001b[38;5;241m=\u001b[39m\u001b[43mobject_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExportFormat\u001b[49m\u001b[38;5;241m.\u001b[39mSAVED_MODEL)\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'tflite_model_maker.object_detector' has no attribute 'ExportFormat'"
          ]
        }
      ],
      "source": [
        "model_path = './saved_model'\n",
        "model.export(export_dir=model_path, export_format=object_detector.ExportFormat.SAVED_MODEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZcBmEigOCO3"
      },
      "source": [
        "### Step 6:  Evaluate the TensorFlow Lite model.\n",
        "\n",
        "Several factors can affect the model accuracy when exporting to TFLite:\n",
        "* [Quantization](https://www.tensorflow.org/lite/performance/model_optimization) helps shrinking the model size by 4 times at the expense of some accuracy drop.\n",
        "* The original TensorFlow model uses per-class [non-max supression (NMS)](https://www.coursera.org/lecture/convolutional-neural-networks/non-max-suppression-dvrjH) for post-processing, while the TFLite model uses global NMS that's much faster but less accurate.\n",
        "Keras outputs maximum 100 detections while tflite outputs maximum 25 detections.\n",
        "\n",
        "Therefore you'll have to evaluate the exported TFLite model and compare its accuracy with the original TensorFlow model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbl8z9_wBPlr",
        "outputId": "a0893077-28d8-4362-89f2-d5197222ac79"
      },
      "outputs": [],
      "source": [
        "model.evaluate_tflite('android.tflite', val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "v7zgUkdOUUnD",
        "outputId": "03467f8e-1a52-41c1-d596-93fa75ce1fb6"
      },
      "outputs": [],
      "source": [
        "# Download the TFLite model to your local computer.\n",
        "from google.colab import files\n",
        "files.download('android.tflite')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnqktl45PZRy"
      },
      "source": [
        "## Test the Android figurine detection model\n",
        "\n",
        "After training the model, let's test it with an image that the model hasn't seen before to get a sense of how good the model is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9ZsLQtJ1AlW_"
      },
      "outputs": [],
      "source": [
        "#@title Load the trained TFLite model and define some visualization functions\n",
        "\n",
        "#@markdown This code comes from the TFLite Object Detection [Raspberry Pi sample](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/raspberry_pi).\n",
        "\n",
        "import platform\n",
        "from typing import List, NamedTuple\n",
        "import json\n",
        "\n",
        "import cv2\n",
        "\n",
        "Interpreter = tf.lite.Interpreter\n",
        "load_delegate = tf.lite.experimental.load_delegate\n",
        "\n",
        "# pylint: enable=g-import-not-at-top\n",
        "\n",
        "\n",
        "class ObjectDetectorOptions(NamedTuple):\n",
        "  \"\"\"A config to initialize an object detector.\"\"\"\n",
        "\n",
        "  enable_edgetpu: bool = False\n",
        "  \"\"\"Enable the model to run on EdgeTPU.\"\"\"\n",
        "\n",
        "  label_allow_list: List[str] = None\n",
        "  \"\"\"The optional allow list of labels.\"\"\"\n",
        "\n",
        "  label_deny_list: List[str] = None\n",
        "  \"\"\"The optional deny list of labels.\"\"\"\n",
        "\n",
        "  max_results: int = -1\n",
        "  \"\"\"The maximum number of top-scored detection results to return.\"\"\"\n",
        "\n",
        "  num_threads: int = 1\n",
        "  \"\"\"The number of CPU threads to be used.\"\"\"\n",
        "\n",
        "  score_threshold: float = 0.0\n",
        "  \"\"\"The score threshold of detection results to return.\"\"\"\n",
        "\n",
        "\n",
        "class Rect(NamedTuple):\n",
        "  \"\"\"A rectangle in 2D space.\"\"\"\n",
        "  left: float\n",
        "  top: float\n",
        "  right: float\n",
        "  bottom: float\n",
        "\n",
        "\n",
        "class Category(NamedTuple):\n",
        "  \"\"\"A result of a classification task.\"\"\"\n",
        "  label: str\n",
        "  score: float\n",
        "  index: int\n",
        "\n",
        "\n",
        "class Detection(NamedTuple):\n",
        "  \"\"\"A detected object as the result of an ObjectDetector.\"\"\"\n",
        "  bounding_box: Rect\n",
        "  categories: List[Category]\n",
        "\n",
        "\n",
        "def edgetpu_lib_name():\n",
        "  \"\"\"Returns the library name of EdgeTPU in the current platform.\"\"\"\n",
        "  return {\n",
        "      'Darwin': 'libedgetpu.1.dylib',\n",
        "      'Linux': 'libedgetpu.so.1',\n",
        "      'Windows': 'edgetpu.dll',\n",
        "  }.get(platform.system(), None)\n",
        "\n",
        "\n",
        "class ObjectDetector:\n",
        "  \"\"\"A wrapper class for a TFLite object detection model.\"\"\"\n",
        "\n",
        "  _OUTPUT_LOCATION_NAME = 'location'\n",
        "  _OUTPUT_CATEGORY_NAME = 'category'\n",
        "  _OUTPUT_SCORE_NAME = 'score'\n",
        "  _OUTPUT_NUMBER_NAME = 'number of detections'\n",
        "\n",
        "  def __init__(\n",
        "      self,\n",
        "      model_path: str,\n",
        "      options: ObjectDetectorOptions = ObjectDetectorOptions()\n",
        "  ) -> None:\n",
        "    \"\"\"Initialize a TFLite object detection model.\n",
        "    Args:\n",
        "        model_path: Path to the TFLite model.\n",
        "        options: The config to initialize an object detector. (Optional)\n",
        "    Raises:\n",
        "        ValueError: If the TFLite model is invalid.\n",
        "        OSError: If the current OS isn't supported by EdgeTPU.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load metadata from model.\n",
        "    displayer = metadata.MetadataDisplayer.with_model_file(model_path)\n",
        "\n",
        "    # Save model metadata for preprocessing later.\n",
        "    model_metadata = json.loads(displayer.get_metadata_json())\n",
        "    process_units = model_metadata['subgraph_metadata'][0]['input_tensor_metadata'][0]['process_units']\n",
        "    mean = 0.0\n",
        "    std = 1.0\n",
        "    for option in process_units:\n",
        "      if option['options_type'] == 'NormalizationOptions':\n",
        "        mean = option['options']['mean'][0]\n",
        "        std = option['options']['std'][0]\n",
        "    self._mean = mean\n",
        "    self._std = std\n",
        "\n",
        "    # Load label list from metadata.\n",
        "    file_name = displayer.get_packed_associated_file_list()[0]\n",
        "    label_map_file = displayer.get_associated_file_buffer(file_name).decode()\n",
        "    label_list = list(filter(lambda x: len(x) > 0, label_map_file.splitlines()))\n",
        "    self._label_list = label_list\n",
        "\n",
        "    # Initialize TFLite model.\n",
        "    if options.enable_edgetpu:\n",
        "      if edgetpu_lib_name() is None:\n",
        "        raise OSError(\"The current OS isn't supported by Coral EdgeTPU.\")\n",
        "      interpreter = Interpreter(\n",
        "          model_path=model_path,\n",
        "          experimental_delegates=[load_delegate(edgetpu_lib_name())],\n",
        "          num_threads=options.num_threads)\n",
        "    else:\n",
        "      interpreter = Interpreter(\n",
        "          model_path=model_path, num_threads=options.num_threads)\n",
        "\n",
        "    interpreter.allocate_tensors()\n",
        "    input_detail = interpreter.get_input_details()[0]\n",
        "\n",
        "    # From TensorFlow 2.6, the order of the outputs become undefined.\n",
        "    # Therefore we need to sort the tensor indices of TFLite outputs and to know\n",
        "    # exactly the meaning of each output tensor. For example, if\n",
        "    # output indices are [601, 599, 598, 600], tensor names and indices aligned\n",
        "    # are:\n",
        "    #   - location: 598\n",
        "    #   - category: 599\n",
        "    #   - score: 600\n",
        "    #   - detection_count: 601\n",
        "    # because of the op's ports of TFLITE_DETECTION_POST_PROCESS\n",
        "    # (https://github.com/tensorflow/tensorflow/blob/a4fe268ea084e7d323133ed7b986e0ae259a2bc7/tensorflow/lite/kernels/detection_postprocess.cc#L47-L50).\n",
        "    sorted_output_indices = sorted(\n",
        "        [output['index'] for output in interpreter.get_output_details()])\n",
        "    self._output_indices = {\n",
        "        self._OUTPUT_LOCATION_NAME: sorted_output_indices[0],\n",
        "        self._OUTPUT_CATEGORY_NAME: sorted_output_indices[1],\n",
        "        self._OUTPUT_SCORE_NAME: sorted_output_indices[2],\n",
        "        self._OUTPUT_NUMBER_NAME: sorted_output_indices[3],\n",
        "    }\n",
        "\n",
        "    self._input_size = input_detail['shape'][2], input_detail['shape'][1]\n",
        "    self._is_quantized_input = input_detail['dtype'] == np.uint8\n",
        "    self._interpreter = interpreter\n",
        "    self._options = options\n",
        "\n",
        "  def detect(self, input_image: np.ndarray) -> List[Detection]:\n",
        "    \"\"\"Run detection on an input image.\n",
        "    Args:\n",
        "        input_image: A [height, width, 3] RGB image. Note that height and width\n",
        "          can be anything since the image will be immediately resized according\n",
        "          to the needs of the model within this function.\n",
        "    Returns:\n",
        "        A Person instance.\n",
        "    \"\"\"\n",
        "    image_height, image_width, _ = input_image.shape\n",
        "\n",
        "    input_tensor = self._preprocess(input_image)\n",
        "\n",
        "    self._set_input_tensor(input_tensor)\n",
        "    self._interpreter.invoke()\n",
        "\n",
        "    # Get all output details\n",
        "    boxes = self._get_output_tensor(self._OUTPUT_LOCATION_NAME)\n",
        "    classes = self._get_output_tensor(self._OUTPUT_CATEGORY_NAME)\n",
        "    scores = self._get_output_tensor(self._OUTPUT_SCORE_NAME)\n",
        "    count = int(self._get_output_tensor(self._OUTPUT_NUMBER_NAME))\n",
        "\n",
        "    return self._postprocess(boxes, classes, scores, count, image_width,\n",
        "                             image_height)\n",
        "\n",
        "  def _preprocess(self, input_image: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Preprocess the input image as required by the TFLite model.\"\"\"\n",
        "\n",
        "    # Resize the input\n",
        "    input_tensor = cv2.resize(input_image, self._input_size)\n",
        "\n",
        "    # Normalize the input if it's a float model (aka. not quantized)\n",
        "    if not self._is_quantized_input:\n",
        "      input_tensor = (np.float32(input_tensor) - self._mean) / self._std\n",
        "\n",
        "    # Add batch dimension\n",
        "    input_tensor = np.expand_dims(input_tensor, axis=0)\n",
        "\n",
        "    return input_tensor\n",
        "\n",
        "  def _set_input_tensor(self, image):\n",
        "    \"\"\"Sets the input tensor.\"\"\"\n",
        "    tensor_index = self._interpreter.get_input_details()[0]['index']\n",
        "    input_tensor = self._interpreter.tensor(tensor_index)()[0]\n",
        "    input_tensor[:, :] = image\n",
        "\n",
        "  def _get_output_tensor(self, name):\n",
        "    \"\"\"Returns the output tensor at the given index.\"\"\"\n",
        "    output_index = self._output_indices[name]\n",
        "    tensor = np.squeeze(self._interpreter.get_tensor(output_index))\n",
        "    return tensor\n",
        "\n",
        "  def _postprocess(self, boxes: np.ndarray, classes: np.ndarray,\n",
        "                   scores: np.ndarray, count: int, image_width: int,\n",
        "                   image_height: int) -> List[Detection]:\n",
        "    \"\"\"Post-process the output of TFLite model into a list of Detection objects.\n",
        "    Args:\n",
        "        boxes: Bounding boxes of detected objects from the TFLite model.\n",
        "        classes: Class index of the detected objects from the TFLite model.\n",
        "        scores: Confidence scores of the detected objects from the TFLite model.\n",
        "        count: Number of detected objects from the TFLite model.\n",
        "        image_width: Width of the input image.\n",
        "        image_height: Height of the input image.\n",
        "    Returns:\n",
        "        A list of Detection objects detected by the TFLite model.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    # Parse the model output into a list of Detection entities.\n",
        "    for i in range(count):\n",
        "      if scores[i] >= self._options.score_threshold:\n",
        "        y_min, x_min, y_max, x_max = boxes[i]\n",
        "        bounding_box = Rect(\n",
        "            top=int(y_min * image_height),\n",
        "            left=int(x_min * image_width),\n",
        "            bottom=int(y_max * image_height),\n",
        "            right=int(x_max * image_width))\n",
        "        class_id = int(classes[i])\n",
        "        category = Category(\n",
        "            score=scores[i],\n",
        "            label=self._label_list[class_id],  # 0 is reserved for background\n",
        "            index=class_id)\n",
        "        result = Detection(bounding_box=bounding_box, categories=[category])\n",
        "        results.append(result)\n",
        "\n",
        "    # Sort detection results by score ascending\n",
        "    sorted_results = sorted(\n",
        "        results,\n",
        "        key=lambda detection: detection.categories[0].score,\n",
        "        reverse=True)\n",
        "\n",
        "    # Filter out detections in deny list\n",
        "    filtered_results = sorted_results\n",
        "    if self._options.label_deny_list is not None:\n",
        "      filtered_results = list(\n",
        "          filter(\n",
        "              lambda detection: detection.categories[0].label not in self.\n",
        "              _options.label_deny_list, filtered_results))\n",
        "\n",
        "    # Keep only detections in allow list\n",
        "    if self._options.label_allow_list is not None:\n",
        "      filtered_results = list(\n",
        "          filter(\n",
        "              lambda detection: detection.categories[0].label in self._options.\n",
        "              label_allow_list, filtered_results))\n",
        "\n",
        "    # Only return maximum of max_results detection.\n",
        "    if self._options.max_results > 0:\n",
        "      result_count = min(len(filtered_results), self._options.max_results)\n",
        "      filtered_results = filtered_results[:result_count]\n",
        "\n",
        "    return filtered_results\n",
        "\n",
        "\n",
        "_MARGIN = 10  # pixels\n",
        "_ROW_SIZE = 10  # pixels\n",
        "_FONT_SIZE = 1\n",
        "_FONT_THICKNESS = 1\n",
        "_TEXT_COLOR = (0, 0, 255)  # red\n",
        "\n",
        "\n",
        "def visualize(\n",
        "    image: np.ndarray,\n",
        "    detections: List[Detection],\n",
        ") -> np.ndarray:\n",
        "  \"\"\"Draws bounding boxes on the input image and return it.\n",
        "  Args:\n",
        "    image: The input RGB image.\n",
        "    detections: The list of all \"Detection\" entities to be visualize.\n",
        "  Returns:\n",
        "    Image with bounding boxes.\n",
        "  \"\"\"\n",
        "  for detection in detections:\n",
        "    # Draw bounding_box\n",
        "    start_point = detection.bounding_box.left, detection.bounding_box.top\n",
        "    end_point = detection.bounding_box.right, detection.bounding_box.bottom\n",
        "    cv2.rectangle(image, start_point, end_point, _TEXT_COLOR, 3)\n",
        "\n",
        "    # Draw label and score\n",
        "    category = detection.categories[0]\n",
        "    class_name = category.label\n",
        "    probability = round(category.score, 2)\n",
        "    result_text = class_name + ' (' + str(probability) + ')'\n",
        "    text_location = (_MARGIN + detection.bounding_box.left,\n",
        "                     _MARGIN + _ROW_SIZE + detection.bounding_box.top)\n",
        "    cv2.putText(image, result_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
        "                _FONT_SIZE, _TEXT_COLOR, _FONT_THICKNESS)\n",
        "\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "1t1z2fKlAoB0",
        "outputId": "97e3d3d1-3168-4f6c-a754-ca1e6cf4f4a7"
      },
      "outputs": [],
      "source": [
        "#@title Run object detection and show the detection results\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "INPUT_IMAGE_URL = \"http://download.tensorflow.org/example_images/android_figurine.jpg\" #@param {type:\"string\"}\n",
        "DETECTION_THRESHOLD = 0.5 #@param {type:\"number\"}\n",
        "TFLITE_MODEL_PATH = \"android.tflite\" #@param {type:\"string\"}\n",
        "\n",
        "TEMP_FILE = '/tmp/image.png'\n",
        "\n",
        "!wget -q -O $TEMP_FILE $INPUT_IMAGE_URL\n",
        "image = Image.open(TEMP_FILE).convert('RGB')\n",
        "image.thumbnail((512, 512), Image.ANTIALIAS)\n",
        "image_np = np.asarray(image)\n",
        "\n",
        "# Load the TFLite model\n",
        "options = ObjectDetectorOptions(\n",
        "      num_threads=4,\n",
        "      score_threshold=DETECTION_THRESHOLD,\n",
        ")\n",
        "detector = ObjectDetector(model_path=TFLITE_MODEL_PATH, options=options)\n",
        "\n",
        "# Run object detection estimation using the model.\n",
        "detections = detector.detect(image_np)\n",
        "\n",
        "# Draw keypoints and edges on input image\n",
        "image_np = visualize(image_np, detections)\n",
        "\n",
        "# Show the detection result\n",
        "Image.fromarray(image_np)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWP3fEPaGNvd"
      },
      "source": [
        "## Compile the model for EdgeTPU\n",
        "\n",
        "Finally, we'll compile the model using `edgetpu_compiler` so that the model can run on [Google Coral EdgeTPU](https://coral.ai/).\n",
        "\n",
        "We start with installing the EdgeTPU compiler on Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK6AN1xVAsCb",
        "outputId": "0a199dc3-a4df-4b4b-ef2b-b9d88b14cb53"
      },
      "outputs": [],
      "source": [
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIGSdzXkEzrj"
      },
      "source": [
        "**Note:** When training the model using a custom dataset, beware that if your dataset includes more than 20 classes, you'll probably have slower inference speeds compared to if you have fewer classes. This is due to an aspect of the EfficientDet architecture in which a certain layer cannot compile for the Edge TPU when it carries more than 20 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzF6u0FZTAjF"
      },
      "source": [
        "Before compiling the `.tflite` file for the Edge TPU, it's important to consider whether your model will fit into the Edge TPU memory.\n",
        "\n",
        "The Edge TPU has approximately 8 MB of SRAM for [caching model paramaters](https://coral.ai/docs/edgetpu/compiler/#parameter-data-caching), so any model close to or over 8 MB will not fit onto the Edge TPU memory. That means the inference times are longer, because some model parameters must be fetched from the host system memory.\n",
        "\n",
        "One way to elimiate the extra latency is to use [model pipelining](https://coral.ai/docs/edgetpu/pipeline/), which splits the model into segments that can run on separate Edge TPUs in series. This can significantly reduce the latency for big models.\n",
        "\n",
        "The following table provides recommendations for the number of Edge TPUs to use with each EfficientDet-Lite model.\n",
        "\n",
        "| Model architecture | Minimum TPUs | Recommended TPUs\n",
        "|--------------------|-------|-------|\n",
        "| EfficientDet-Lite0 | 1     | 1     |\n",
        "| EfficientDet-Lite1 | 1     | 1     |\n",
        "| EfficientDet-Lite2 | 1     | 2     |\n",
        "| EfficientDet-Lite3 | 2     | 2     |\n",
        "| EfficientDet-Lite4 | 2     | 3     |\n",
        "\n",
        "If you need extra Edge TPUs for your model, then update `NUMBER_OF_TPUS` here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyptUjakAwzz",
        "outputId": "7a3dad3b-eeb4-45e1-fb68-f0436ac5a933"
      },
      "outputs": [],
      "source": [
        "NUMBER_OF_TPUS = 1\n",
        "\n",
        "!edgetpu_compiler android.tflite --num_segments=$NUMBER_OF_TPUS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJYXucYWTGqZ"
      },
      "source": [
        "Finally, we'll copy the metadata, including the label file, from the original TensorFlow Lite model to the EdgeTPU model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LY1WrgMJBFd"
      },
      "outputs": [],
      "source": [
        "populator_dst = metadata.MetadataPopulator.with_model_file('android_edgetpu.tflite')\n",
        "\n",
        "with open('android.tflite', 'rb') as f:\n",
        "  populator_dst.load_metadata_and_associated_files(f.read())\n",
        "\n",
        "populator_dst.populate()\n",
        "updated_model_buf = populator_dst.get_model_buffer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VdRihInCJ3ie",
        "outputId": "f2c37370-6ec3-41e6-903d-22e49e2f7dea"
      },
      "outputs": [],
      "source": [
        "# Download the TFLite model compiled for EdgeTPU to your local computer.\n",
        "from google.colab import files\n",
        "files.download('android_edgetpu.tflite')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Model Maker Object Detection for Android Figurine",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
